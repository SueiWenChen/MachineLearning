{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65aca2b6",
   "metadata": {},
   "source": [
    "# CNN on Road Sign Classification\n",
    "\n",
    "This notebook contains a CNN which classifies 4 types of road signs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bc2997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41dcaa6",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb14c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function loads the images and create training data\n",
    "labels=['1','2','3','4']\n",
    "DATADIR = './RoadSign'\n",
    "def create_training_data(training_set, img_height, img_width):\n",
    "    for label in labels:\n",
    "        path=os.path.join(DATADIR, label) # get dir of the folder for the current class\n",
    "        category = int(label)-1 # index starts from 0\n",
    "        for img in os.listdir(path): # for each image\n",
    "            img_array = cv2.imread(os.path.join(path, img)) # read the image as 3-d array\n",
    "            img_array = cv2.resize(img_array, (img_height, img_width)) # resize the image to the min size\n",
    "            training_set.append([img_array, category]) # add this image to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a21c0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sizes of all the images to compute the minimum height and width\n",
    "import PIL\n",
    "width_list = []\n",
    "height_list = []\n",
    "os.chdir('./data')\n",
    "for i in range(1,5):\n",
    "    os.chdir(\"./{num}\".format(num=i))\n",
    "    for file in os.listdir():\n",
    "        image = PIL.Image.open(file)\n",
    "        width, height = image.size\n",
    "        width_list.append(width)\n",
    "        height_list.append(height)\n",
    "    os.chdir('..')\n",
    "os.chdir('..')\n",
    "# compute the smallest height and width\n",
    "width = np.min(width_list)\n",
    "height = np.min(height_list)\n",
    "IMG_SIZE = np.min([width, height])\n",
    "print('IMG_SIZE=', IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2c7a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the training set\n",
    "training_data = []            \n",
    "create_training_data(training_data, IMG_SIZE, IMG_SIZE)\n",
    "random.shuffle(training_data) # randomly shuffle the training pais\n",
    "X = [] # features\n",
    "y = [] # labels\n",
    "for img, label in training_data:\n",
    "    X.append(img)\n",
    "    y.append(label)\n",
    "X = np.array(X) # feature array\n",
    "y = np.array(y).reshape(-1,1) # label array\n",
    "y = keras.utils.to_categorical(y) # convert class number to one-hot encoding\n",
    "print(np.shape(X), np.shape(y)) # check if their shapes are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107bdaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the images and labels to check if they are loaded correctly\n",
    "fig, ax = plt.subplots(1,10)\n",
    "for i in range(10):\n",
    "    ax[i].imshow(X[i])    \n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "    print(y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4815ee98",
   "metadata": {},
   "source": [
    "### Defining CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eee86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=(3,3), padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=None))\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=None))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b2a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=SGD(learning_rate=0.001),loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71029652",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 30\n",
    "\n",
    "# now that we have X and y, we fit the model\n",
    "model.fit( X, y, batch_size= batch_size, epochs=epochs, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

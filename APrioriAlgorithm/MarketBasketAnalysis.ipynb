{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af344db",
   "metadata": {},
   "source": [
    "# Market Basket Analysis\n",
    "This notebook contains an implementation of A Priori Algorithm. Datasets are taken from :\n",
    "- https://github.com/jzuniga123/SPS/blob/master/DATA%20624/GroceryDataSet.csv \n",
    "- https://www.kaggle.com/shwetabh123/basketballoptimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff9a98a",
   "metadata": {},
   "source": [
    "## Loading data and format conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f72b898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926d5f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file and store all items in the list \"items\"\n",
    "path = 'Market_Basket_Optimisation.csv'\n",
    "items = [] # list of all items\n",
    "try:\n",
    "    f = open(path, 'r')\n",
    "    rows = csv.reader(f, delimiter=',')\n",
    "    for row in rows:\n",
    "        row = [item for item in row if item!=''] # remove redundant entries\n",
    "        items = items + row\n",
    "        # print(row)\n",
    "    f.close()\n",
    "except:\n",
    "    print('ERROR: can not found ' + path)\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68137ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zucchini', 'green beans', 'fresh tuna', 'burger sauce', 'ham', 'black tea', 'tomato sauce', 'eggplant', 'whole wheat rice', 'yogurt cake', 'white wine', 'chili', 'mint', 'blueberries', 'fromage blanc', 'burgers', 'bacon', 'pancakes', 'light mayo', 'hand protein bar', 'cottage cheese', 'chocolate bread', 'red wine', 'shrimp', 'cauliflower', 'whole weat flour', 'strong cheese', 'tomato juice', 'fresh bread', 'spaghetti', 'herb & pepper', 'cider', 'grated cheese', 'chutney', 'babies food', 'energy bar', 'soup', 'tea', 'body spray', 'salt', 'ketchup', 'parmesan cheese', 'hot dogs', 'melons', 'mashed potato', 'bramble', 'candy bars', 'light cream', 'dessert wine', 'frozen smoothie', 'energy drink', 'muffins', 'barbecue sauce', 'ground beef', 'avocado', 'green grapes', 'shallot', 'brownies', 'gluten free bar', 'frozen vegetables', 'french wine', 'napkins', 'pickles', 'pasta', 'bug spray', 'cream', 'oil', 'pet food', 'spinach', 'cookies', 'rice', 'corn', 'olive oil', 'carrots', 'asparagus', 'shampoo', 'salmon', 'strawberries', 'antioxydant juice', 'soda', 'gums', 'nonfat milk', 'honey', 'chocolate', 'butter', 'low fat yogurt', 'flax seed', 'water spray', 'toothpaste', 'escalope', 'cereals', 'almonds', 'chicken', 'yams', 'meatballs', 'eggs', 'mineral water', 'champagne', 'cooking oil', 'sandwich', 'mayonnaise', 'magazines', 'cake', 'pepper', 'oatmeal', 'milk', 'whole wheat pasta', 'clothes accessories', 'salad', 'vegetables mix', 'green tea', 'sparkling water', 'mushroom cream sauce', 'turkey', 'french fries', 'tomatoes', 'extra dark chocolate', 'mint green tea', 'protein bar']\n"
     ]
    }
   ],
   "source": [
    "# remove redundant entries in items\n",
    "itemset = set(items) # remove duplicate entries\n",
    "items = list(itemset) # convert back to list\n",
    "print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a0bd955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert each basket to one-hot encoding\n",
    "f = open(path, 'r')\n",
    "rows = csv.reader(f, delimiter=',')\n",
    "data = [] # matrix to store data\n",
    "n = len(items) # number of items\n",
    "for row in rows: # for each customer\n",
    "    row = [item for item in row if item!='']\n",
    "    basket = [0]*n # initialize each item to be nonpresent\n",
    "    for item in row: # for each item\n",
    "        basket[items.index(item)] = 1 # the item is present\n",
    "    data.append(basket) # add to data\n",
    "f.close()\n",
    "data = np.array(data) # convert to numpy array\n",
    "# # check if the conversion is correct by inspecting the first basket\n",
    "# for index in np.argwhere(data[0]>0).flatten():\n",
    "#     print(items[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b0e77e",
   "metadata": {},
   "source": [
    "## Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ed6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def support(data):\n",
    "    '''return the support of a 2d array with each row being one data point'''\n",
    "    m = data.shape[0] # number of data points\n",
    "    n = data.shape[1] # number of variables\n",
    "    templist = np.zeros(m)\n",
    "    for i in range(m): # for each row\n",
    "        temp = 1\n",
    "        for j in range(n): # for each column\n",
    "            temp *= data[i][j]\n",
    "        templist[i] = temp\n",
    "    supp = sum(templist)/m\n",
    "    return supp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c48cba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FindHighSupportSubset(data, t):\n",
    "    '''This function takes in binary numpy array \"data\" in market basket analysis and the support threshold t, and\n",
    "    it returns a list \"itemsetList\" of sets whose k-th position is a set of tuples encoding subsets of itemset \n",
    "    with size k with support > t\n",
    "    '''\n",
    "    # set up parameters\n",
    "    numBaskets = data.shape[0] # number of baskets\n",
    "    numItems   = data.shape[1] # number of items\n",
    "    items = np.arange(numItems) # indicies of items\n",
    "    itemsetList = [] # initialize list to return\n",
    "    \n",
    "    # compute all size 1 itemsets\n",
    "    supp = np.sum(data, axis=0)/numBaskets # compute the support for each singleton itemset\n",
    "    singletons = np.argwhere(supp>0.05).flatten() # store the indicies as an array\n",
    "    itemsetList.append(set(singletons))\n",
    "    n0 = len(singletons) # number of qualified singletons\n",
    "    # compute all size 2 itemsets\n",
    "    tempset = set()\n",
    "    for i in range(n0): # for each singleton\n",
    "        for j in range(i+1, n0): # for each pair of singleton\n",
    "            supp = support(data[:,[i,j]]) # compute the support\n",
    "            if supp > t: # if support is larger than the threshold\n",
    "                tempset = tempset | {(i,j)}   # add the pair to the qualified itemsets\n",
    "    if len(tempset)!=0: # if the set is not empty\n",
    "        itemsetList.append(tempset)\n",
    "    else:\n",
    "        return itemsetList  # no bigger subsets possible\n",
    "\n",
    "    # iteratively populate itemsetList  \n",
    "    for k in range(2,numItems): # for each k corresponding to subset of size k+1\n",
    "        tempset = set()\n",
    "        for subsetk in itemsetList[k-1]: # for each subset of size k\n",
    "            for item in singletons: # for each singleton itemset\n",
    "                if item not in subsetk: # if singleton not in subset\n",
    "                    index = list(subsetk) + [item] # join the indices as a list\n",
    "                    supp = support(data[:, index]) # compute the support\n",
    "                    # print(index, supp, supp>t)\n",
    "                    if supp > t: # if support is larger than the threshold\n",
    "                        index = np.sort(index) # sort the index\n",
    "                        tempset = tempset | {tuple(index)} # convert to tuple and add to the qualified subsets\n",
    "        if len(tempset)!=0: # if there is some qualified subset\n",
    "            itemsetList.append(tempset) # add to list\n",
    "        else:\n",
    "            return itemsetList  # no bigger subsets possible\n",
    "    return itemsetList "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "622ae825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence(data, A, B):\n",
    "    '''return the confidence of the association rule A=>B, where A and B are sets of indices'''\n",
    "    return support(data[:,list(A|B)]) / support(data[:,list(B)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c746a10f",
   "metadata": {},
   "source": [
    "## Apply to dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b73e57",
   "metadata": {},
   "source": [
    "Dataset 'Market_Basket_Optimisation.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41a8e717",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{(15, 17), (17, 23)}]\n"
     ]
    }
   ],
   "source": [
    "itemsetList = FindHighSupportSubset(data, 0.01)\n",
    "print(itemsetList[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81fc39f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "burgers pancakes shrimp\n",
      "0.11079943899018233 0.14738805970149252\n"
     ]
    }
   ],
   "source": [
    "# explore\n",
    "print(items[15], items[17], items[23])\n",
    "print(confidence(data, {15}, {17}), confidence(data, {17}, {23}), )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85174c2",
   "metadata": {},
   "source": [
    "Dataset 'GrocerydataSet.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d28b1f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv file\n",
    "path = 'GroceryDataSet.csv'\n",
    "items = [] # list of all items\n",
    "try:\n",
    "    f = open(path, 'r')\n",
    "    rows = csv.reader(f, delimiter=',')\n",
    "    for row in rows:\n",
    "        row = [item for item in row if item!='']\n",
    "        items = items + row\n",
    "        # print(row)\n",
    "    f.close()\n",
    "except:\n",
    "    print('ERROR: can not found ' + path)\n",
    "    exit(1)\n",
    "\n",
    "itemset = set(items) # remove duplicate entries\n",
    "items = list(itemset) # convert back to list\n",
    "\n",
    "# convert each basket to one-hot encoding\n",
    "f = open(path, 'r')\n",
    "rows = csv.reader(f, delimiter=',')\n",
    "data = [] # matrix to store data\n",
    "n = len(items) # number of items\n",
    "for row in rows: # for each customer\n",
    "    basket = [0]*n\n",
    "    row = [item for item in row if item!='']\n",
    "    for item in row: # for each item\n",
    "        basket[items.index(item)] = 1 # the item is present\n",
    "    data.append(basket) # add to data\n",
    "f.close()\n",
    "data = np.array(data) # convert to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8230b583",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{(12, 21)}]\n"
     ]
    }
   ],
   "source": [
    "itemsetList = FindHighSupportSubset(data, 0.01)\n",
    "print(itemsetList[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fb0f8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root vegetables \t sausage\n",
      "0.1590909090909091\n"
     ]
    }
   ],
   "source": [
    "print(items[12],'\\t', items[21])\n",
    "print(confidence(data, {12}, {21}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
